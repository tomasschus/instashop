# ğŸ—ï¸ InstaShop Big Data Pipeline - Arquitectura

## ğŸ“Š Diagrama de Arquitectura

```mermaid
graph TB
    %% GeneraciÃ³n de Datos
    subgraph "ğŸ“Š GeneraciÃ³n de Datos"
        DG[realistic_data_generator.py]
        DG --> |"Transacciones + Eventos"| PG1[(PostgreSQL<br/>instashop)]
        DG --> |"Interacciones CRM"| PG2[(PostgreSQL<br/>crm_db)]
    end

    %% Kafka Producer
    subgraph "ğŸ“¤ Kafka Producer"
        KP[dynamic_producer.py]
        PG1 --> |"Consulta cada 2s<br/>Ventana: 2 min"| KP
        PG2 --> |"Consulta cada 2s<br/>Ventana: 2 min"| KP
    end

    %% Kafka Cluster
    subgraph "ğŸ“¨ Kafka Cluster"
        K1[kafka1:9092]
        K2[kafka2:9093]
        K3[kafka3:9094]
        
        KP --> |"transactions"| K1
        KP --> |"user_behavior"| K2
        KP --> |"searches"| K3
        KP --> |"cart_events"| K1
    end

    %% Kafka Consumer
    subgraph "ğŸ“¥ Kafka Consumer"
        KC[dynamic_consumer.py]
        K1 --> KC
        K2 --> KC
        K3 --> KC
    end

    %% Data Warehouse
    subgraph "ğŸ¢ Data Warehouse"
        DWH[(PostgreSQL<br/>dwh_db)]
        KC --> |"realtime_events"| DWH
        KC --> |"transaction_items<br/>enriquecidos"| K1
    end

    %% Spark Streaming
    subgraph "âš¡ Spark Streaming"
        SS[realtime_metrics_producer.py]
        K1 --> |"transactions"| SS
        K2 --> |"user_behavior"| SS
        K1 --> |"transaction_items"| SS
    end

    %% Redis
    subgraph "ğŸ’¾ Redis Cache"
        RD[(Redis<br/>redis-metrics)]
        SS --> |"MÃ©tricas en tiempo real"| RD
    end

    %% Dashboard
    subgraph "ğŸ“Š Dashboard"
        DS[realtime_spark_dashboard.py]
        RD --> |"MÃ©tricas en tiempo real"| DS
        DWH --> |"Datos histÃ³ricos"| DS
    end

    %% Usuario
    USER[ğŸ‘¤ Usuario] --> |"http://localhost:8501"| DS

    %% Estilos
    classDef generator fill:#e1f5fe
    classDef kafka fill:#fff3e0
    classDef database fill:#f3e5f5
    classDef spark fill:#e8f5e8
    classDef dashboard fill:#fff8e1

    class DG,KP generator
    class K1,K2,K3,KC kafka
    class PG1,PG2,DWH,RD database
    class SS spark
    class DS,USER dashboard
```

## ğŸ”„ Flujo de Datos Detallado

### **1. GeneraciÃ³n de Datos (realistic_data_generator.py)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Generador     â”‚â”€â”€â”€â–¶â”‚   PostgreSQL    â”‚
â”‚   - Transaccionesâ”‚    â”‚   instashop     â”‚
â”‚   - Comportamientoâ”‚   â”‚   crm_db        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **2. Producer Kafka (dynamic_producer.py)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚â”€â”€â”€â–¶â”‚   Producer      â”‚
â”‚   - Consulta 2s â”‚    â”‚   - Sin duplicadosâ”‚
â”‚   - Ventana 2minâ”‚    â”‚   - Todos topicsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **3. Kafka Cluster**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Producer      â”‚â”€â”€â”€â–¶â”‚   Kafka Topics  â”‚
â”‚                 â”‚    â”‚   - transactions â”‚
â”‚                 â”‚    â”‚   - user_behaviorâ”‚
â”‚                 â”‚    â”‚   - searches     â”‚
â”‚                 â”‚    â”‚   - cart_events  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **4. Consumer Kafka (dynamic_consumer.py)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka Topics  â”‚â”€â”€â”€â–¶â”‚   Consumer      â”‚
â”‚                 â”‚    â”‚   - Group ID Ãºnicoâ”‚
â”‚                 â”‚    â”‚   - earliest     â”‚
â”‚                 â”‚    â”‚   - commit manualâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **5. Data Warehouse**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Consumer      â”‚â”€â”€â”€â–¶â”‚   DWH PostgreSQL â”‚
â”‚                 â”‚    â”‚   - realtime_eventsâ”‚
â”‚                 â”‚    â”‚   - Datos histÃ³ricosâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **6. Spark Streaming (realtime_metrics_producer.py)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka Topics  â”‚â”€â”€â”€â–¶â”‚   Spark         â”‚
â”‚                 â”‚    â”‚   - Watermark 10sâ”‚
â”‚                 â”‚    â”‚   - Ventana 30s â”‚
â”‚                 â”‚    â”‚   - Agregacionesâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **7. Redis Cache**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Spark         â”‚â”€â”€â”€â–¶â”‚   Redis         â”‚
â”‚                 â”‚    â”‚   - MÃ©tricas    â”‚
â”‚                 â”‚    â”‚   - TTL 1 hora  â”‚
â”‚                 â”‚    â”‚   - Tiempo real â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **8. Dashboard (realtime_spark_dashboard.py)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Redis + DWH   â”‚â”€â”€â”€â–¶â”‚   Streamlit     â”‚
â”‚                 â”‚    â”‚   - Auto-refreshâ”‚
â”‚                 â”‚    â”‚   - GrÃ¡ficos    â”‚
â”‚                 â”‚    â”‚   - KPIs        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Componentes por Puerto

| Componente | Puerto | DescripciÃ³n |
|------------|--------|-------------|
| **PostgreSQL instashop** | 5432 | Base de datos principal |
| **PostgreSQL crm_db** | 5432 | Base de datos CRM |
| **PostgreSQL dwh_db** | 5436 | Data Warehouse |
| **Kafka kafka1** | 9092 | Broker Kafka 1 |
| **Kafka kafka2** | 9093 | Broker Kafka 2 |
| **Kafka kafka3** | 9094 | Broker Kafka 3 |
| **Redis** | 6379 | Cache de mÃ©tricas |
| **Spark Master** | 8080 | UI de Spark |
| **Streamlit** | 8501 | Dashboard |

## ğŸ”§ Configuraciones Clave

### **Generador**
- **Frecuencia**: 0.1 segundos
- **DistribuciÃ³n**: 70% transacciones, 30% comportamientos
- **Timestamps**: UTC
- **Auto-inicializaciÃ³n**: Tablas y datos bÃ¡sicos

### **Producer**
- **Consulta**: Cada 2 segundos
- **Ventana**: Ãšltimos 2 minutos
- **Duplicados**: Sin protecciÃ³n (envÃ­a todo)
- **Topics**: transactions, user_behavior, searches, cart_events

### **Consumer**
- **Group ID**: Ãšnico por timestamp
- **Offset**: earliest (lee mensajes viejos)
- **Commit**: Manual despuÃ©s de procesar
- **EnvÃ­o adicional**: transaction_items a Kafka

### **Spark**
- **Watermark**: 10 segundos
- **Ventana**: 30 segundos
- **Starting offsets**: earliest
- **MÃ©tricas**: Transacciones, comportamiento, productos

### **Dashboard**
- **Auto-refresh**: Cada 5 segundos
- **Fuentes**: Redis (tiempo real) + DWH (histÃ³rico)
- **GrÃ¡ficos**: KPIs, productos, comportamiento, histÃ³rico
