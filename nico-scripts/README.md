# ğŸš€ InstaShop Big Data Pipeline - Nico Scripts (CDC Architecture)

> ğŸ“Š **Ver diagrama completo**: [ARCHITECTURE.md](./ARCHITECTURE.md)  
> ğŸ—„ï¸ **Ver DER de bases de datos**: [DATABASE_ERD.md](./DATABASE_ERD.md)  
> ğŸ¢ **Ver DER del Data Warehouse**: [DWH_ERD.md](./DWH_ERD.md)

## ğŸ“‹ **Flujo CDC Completo del Pipeline**

### **1. ğŸ“Š GeneraciÃ³n de Datos Realistas**
- **Script**: `realistic_data_generator.py`
- **FunciÃ³n**: Genera transacciones y eventos de comportamiento en tiempo real
- **Datos**: Inserta en PostgreSQL (`instashop`, `crm_db`, `erp_db`, `ecommerce_db`) usando timestamps UTC
- **Frecuencia**: ~10 eventos por segundo (70% transacciones, 30% comportamientos)
- **CaracterÃ­sticas**: Auto-inicializaciÃ³n de tablas, creaciÃ³n de datos bÃ¡sicos, manejo de secuencias PostgreSQL

### **2. ğŸ”„ Debezium Change Data Capture (CDC)**
- **Script**: `setup_debezium.py` + `init_postgres_cdc.py`
- **FunciÃ³n**: ConfiguraciÃ³n automÃ¡tica de Debezium para capturar cambios en PostgreSQL
- **Conectores**: 4 conectores CDC (InstashopDB, CRM, ERP, E-commerce)
- **Topics CDC**: `transaction`, `customer`, `product`, `transactiondetail`, `interaction`, `stock`, `carrier`, `shipment`
- **ConfiguraciÃ³n**: Logical replication, replication slots, publications automÃ¡ticas
- **Plugin**: `pgoutput` (nativo de PostgreSQL)

### **3. ğŸ“¥ CDC Redis Producer**
- **Script**: `cdc_redis_producer.py`
- **FunciÃ³n**: Consume eventos CDC de Debezium y popula mÃ©tricas en Redis
- **Topics**: Todos los tÃ³picos CDC de Debezium
- **Destino**: MÃ©tricas agregadas en Redis para dashboard en tiempo real
- **CaracterÃ­sticas**: Procesamiento de eventos `create`, `update`, `delete`, `read`
- **MÃ©tricas**: Contadores de transacciones, clientes, productos, revenue total/diario

### **4. âš¡ Spark Streaming + Redis**
- **Script**: `spark-streaming/realtime_metrics_producer.py`
- **FunciÃ³n**: Procesa streams CDC de Kafka y envÃ­a mÃ©tricas avanzadas a Redis
- **Topics**: `transaction`, `customer`, `product`, `transaction_items` (renombrado por Debezium)
- **AnÃ¡lisis**: Agregaciones en tiempo real (ventanas de 30 segundos)
- **MÃ©tricas**: AnÃ¡lisis avanzados de transacciones, categorÃ­as, comportamientos
- **Salida**: MÃ©tricas complejas almacenadas en Redis para dashboard

### **5. ğŸ“Š Dashboard Streamlit + Redis + DWH**
- **Script**: `dashboards/realtime_spark_dashboard.py`
- **FunciÃ³n**: VisualizaciÃ³n en tiempo real de mÃ©tricas de Spark y datos histÃ³ricos del DWH
- **Fuentes**: Redis (mÃ©tricas en tiempo real), PostgreSQL DWH (datos histÃ³ricos)
- **CaracterÃ­sticas**: KPIs en tiempo real, grÃ¡ficos dinÃ¡micos, auto-refresh cada 5s
- **URL**: http://localhost:8501

---

## ğŸš€ **Comandos de EjecuciÃ³n CDC**

### **Activar Entorno Virtual**
```bash
source venv/bin/activate
```

### **Levantar Docker**
```bash
docker-compose up -d
```

### **Configurar PostgreSQL para CDC**
```bash
python nico-scripts/init_postgres_cdc.py
```

### **Desplegar Conectores Debezium**
```bash
python nico-scripts/setup_debezium.py
```

### **Generar Eventos en PostgreSQL**
```bash
python nico-scripts/realistic_data_generator.py
```

### **CDC Redis Producer (Terminal 2)**
```bash
python nico-scripts/cdc_redis_producer.py
```

### **Spark Streaming + Redis (Terminal 3)**
```bash
python nico-scripts/spark-streaming/realtime_metrics_producer.py
```

### **Dashboard Real-time (Terminal 4)**
```bash
streamlit run nico-scripts/dashboards/realtime_spark_dashboard.py
```

---

## ğŸ” **Comandos de Monitoreo CDC**

### **Ver Topics CDC de Kafka**
```bash
docker exec kafka1 kafka-topics.sh --list --bootstrap-server localhost:19092
```

### **Ver Mensajes CDC - Transactions**
```bash
docker exec kafka1 kafka-console-consumer.sh --bootstrap-server localhost:19092 --topic transaction --from-beginning --max-messages 1
```

### **Ver Mensajes CDC - Customers**
```bash
docker exec kafka1 kafka-console-consumer.sh --bootstrap-server localhost:19092 --topic customer --from-beginning --max-messages 1
```

### **Ver Estado de Conectores Debezium**
```bash
curl -s http://localhost:8083/connectors | jq
curl -s http://localhost:8083/connectors/instashop-connector/status | jq
```

### **Ver MÃ©tricas CDC en Redis**
```bash
docker exec redis-metrics redis-cli GET "metrics:dashboard"
docker exec redis-metrics redis-cli KEYS "metrics:*"
```

### **Logs de Spark Master**
```bash
docker logs spark-master -f
```

### **Logs de Spark Worker**
```bash
docker logs spark-worker-1 -f
```

### **Ver MÃ©tricas en Redis**
```bash
docker exec -it redis-metrics redis-cli
> KEYS metrics:*
> GET metrics:transactions
```

### **Logs Generales Docker**
```bash
docker-compose logs -f
```

---

## ğŸ“Š **Logs Esperados**

### **Generador de Datos**
```
ğŸš€ Iniciando generaciÃ³n de datos realistas por 60 minutos
ğŸ“Š Estado inicial: 50 clientes, 100 compradores, 200 productos
ğŸ”„ Iniciando bucle de generaciÃ³n de datos...
ğŸ“ˆ Progreso: 50 eventos generados (35 transacciones, 15 comportamientos)
```

### **Producer Kafka**
```
ğŸš€ Dynamic Kafka Producer inicializado
ğŸ“¤ Enviando 8 transacciones a Kafka
ğŸ”„ TransacciÃ³n 1234 con 3 items
âœ… Enviado exitosamente a transactions: transaction - Cliente 28
ğŸ’“ Producer activo - enviando datos a Kafka...
```

### **Consumer Kafka**
```
ğŸš€ Dynamic Kafka Consumer inicializado
ğŸ†” Group ID: instashop-dynamic-group-1694895600
âš™ï¸ Auto offset reset: earliest
ğŸ“¨ Mensaje recibido de topic: transactions, offset: 15
âœ… Evento #1 procesado exitosamente
ğŸ“¤ Enviado transaction_item a Kafka: iPhone 15 (Electronics)
```

### **Spark Streaming + Redis**
```
ğŸš€ Realtime Metrics Producer inicializado
ğŸ“Š Esperando datos de Kafka para procesar...
ğŸ”„ Procesando batch 1 con 5 filas
ğŸ“Š MÃ©tricas de transacciones actualizadas: {'transaction_count': 5, 'total_revenue': 1250.5}
ğŸ“Š MÃ©tricas de productos actualizadas: Electronics = {'product_sales': 3, 'category_revenue': 800.0}
```

### **Dashboard Real-time**
```
âš¡ InstaShop Real-time Spark Metrics
ğŸ• Ãšltima actualizaciÃ³n: 2025-09-16T22:50:00Z
âœ… Redis: Conectado
âœ… Spark: Procesando datos
âœ… Kafka: Datos fluyendo
ğŸ“Š Total de Eventos: 4,796
```

---

## ğŸ¯ **URLs Importantes**
- **Dashboard**: http://localhost:8501
- **Spark UI**: http://localhost:8080
- **Jupyter**: http://localhost:8888

---

## âš™ï¸ **CaracterÃ­sticas TÃ©cnicas**

### **Configuraciones Optimizadas**
- **Generador**: Intervalo de 0.1 segundos, 70% transacciones, timestamps UTC
- **Producer**: Consulta cada 2 segundos, ventana de 2 minutos, sin protecciÃ³n contra duplicados
- **Consumer**: Group ID Ãºnico, `auto_offset_reset='earliest'`, commit manual
- **Spark**: Watermark de 10 segundos, ventanas de 30 segundos, `startingOffsets='earliest'`
- **Dashboard**: Auto-refresh cada 5 segundos, conexiÃ³n a Redis y DWH

### **Dependencias Principales**
- **Python**: 3.8+
- **PostgreSQL**: MÃºltiples instancias (instashop, crm_db, dwh_db)
- **Kafka**: 3 brokers (kafka1, kafka2, kafka3)
- **Spark**: 3.3.4 con Java 17
- **Redis**: Para mÃ©tricas en tiempo real
- **Streamlit**: Para dashboard interactivo

### **Topics CDC de Kafka**
- `transaction`: Eventos CDC de transacciones (InstashopDB)
- `customer`: Eventos CDC de clientes (InstashopDB)
- `product`: Eventos CDC de productos (InstashopDB)
- `transactiondetail`: Eventos CDC de detalles de transacciÃ³n (InstashopDB)
- `interaction`: Eventos CDC de interacciones (CRM)
- `stock`: Eventos CDC de inventario (ERP)
- `carrier`: Eventos CDC de transportistas (E-commerce)
- `shipment`: Eventos CDC de envÃ­os (E-commerce)

---

## ğŸ”§ **Troubleshooting**

### **Consumer no recibe mensajes**
- **Problema**: Consumer configurado con `auto_offset_reset='latest'`
- **SoluciÃ³n**: Cambiar a `auto_offset_reset='earliest'` y usar Group ID Ãºnico

### **Dashboard muestra grÃ¡ficos vacÃ­os**
- **Problema**: `transaction_metrics` vacÃ­o en Redis
- **SoluciÃ³n**: Verificar que Spark estÃ© procesando eventos `transaction_item`

### **Generador falla con errores de foreign key**
- **Problema**: IDs de productos/clientes no existen
- **SoluciÃ³n**: El generador auto-inicializa datos bÃ¡sicos si las tablas estÃ¡n vacÃ­as

### **Spark no encuentra datos**
- **Problema**: `startingOffsets='latest'` en Spark
- **SoluciÃ³n**: Cambiar a `startingOffsets='earliest'` y reducir watermark a 10 segundos

### **Redis sin mÃ©tricas de productos**
- **Problema**: Kafka messages con `items: []` vacÃ­os
- **SoluciÃ³n**: Verificar que el generador inserte `TransactionDetail` correctamente

---

## âš¡ **Comando RÃ¡pido CDC (Todo en Secuencia)**
```bash
# 1. Activar entorno e iniciar servicios
source venv/bin/activate
docker-compose up -d
sleep 60

# 2. Configurar CDC
python nico-scripts/init_postgres_cdc.py
python nico-scripts/setup_debezium.py
sleep 10

# 3. Iniciar pipeline CDC
python nico-scripts/realistic_data_generator.py &
python nico-scripts/cdc_redis_producer.py &
python nico-scripts/spark-streaming/realtime_metrics_producer.py &
streamlit run nico-scripts/dashboards/realtime_spark_dashboard.py
```
