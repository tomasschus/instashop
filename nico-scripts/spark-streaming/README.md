# ğŸš€ Spark Streaming Scripts - CDC Architecture

## ğŸ“‹ **Scripts Disponibles**

### **1. ğŸ“Š CDC Redis Producer**
- **Script**: `cdc_redis_producer.py`
- **FunciÃ³n**: Consumer especializado para eventos CDC de Debezium
- **Entrada**: Topics CDC de Kafka (`transaction`, `customer`, `product`, etc.)
- **Salida**: MÃ©tricas agregadas en Redis para dashboard
- **CaracterÃ­sticas**:
  - âœ… Procesa eventos CDC en tiempo real
  - âœ… Maneja operaciones `create`, `update`, `delete`, `read`
  - âœ… Contador de transacciones, clientes, productos
  - âœ… CÃ¡lculo de revenue total y diario
  - âœ… ActualizaciÃ³n automÃ¡tica cada 5 eventos
  - âœ… Manejo graceful de seÃ±ales (SIGINT/SIGTERM)

### **2. âš¡ Realtime Metrics Producer (Spark)**
- **Script**: `realtime_metrics_producer.py`
- **FunciÃ³n**: Spark Streaming para anÃ¡lisis avanzados
- **Entrada**: Topics CDC de Kafka
- **Salida**: MÃ©tricas complejas en Redis
- **CaracterÃ­sticas**:
  - âœ… Agregaciones en ventanas de tiempo
  - âœ… AnÃ¡lisis por categorÃ­as de productos
  - âœ… MÃ©tricas de comportamiento de usuarios
  - âœ… Watermarks para datos tardÃ­os

### **3. ğŸ“ˆ Simple Metrics Producer**
- **Script**: `simple_metrics_producer.py`
- **FunciÃ³n**: MÃ©tricas bÃ¡sicas sin Spark
- **Uso**: Para pruebas rÃ¡pidas y debugging

### **4. ğŸ“Š Kafka Streaming Analytics**
- **Script**: `kafka_streaming_analytics.py`
- **FunciÃ³n**: AnÃ¡lisis general de streams de Kafka
- **Uso**: AnÃ¡lisis exploratorios y mÃ©tricas personalizadas

---

## ğŸš€ **Uso Recomendado**

### **Para Dashboard en Tiempo Real**
```bash
# Usar CDC Redis Producer (mÃ¡s eficiente)
source venv/bin/activate
python nico-scripts/cdc_redis_producer.py
```

### **Para AnÃ¡lisis Avanzados**
```bash
# Usar Spark Streaming en paralelo
source venv/bin/activate
python nico-scripts/spark-streaming/realtime_metrics_producer.py
```

### **Ejecutar Ambos (ConfiguraciÃ³n Completa)**
```bash
# Terminal 1: CDC Redis Producer
python nico-scripts/cdc_redis_producer.py &

# Terminal 2: Spark Streaming
python nico-scripts/spark-streaming/realtime_metrics_producer.py &
```

---

## ğŸ“Š **MÃ©tricas Generadas**

### **CDC Redis Producer**
```json
{
  "total_transactions": 3207,
  "total_customers": 805,
  "total_products": 2701,
  "total_events": 18884,
  "revenue_total": 125847.50,
  "transactions_today": 45,
  "revenue_today": 2150.75,
  "last_updated": "2025-09-17T02:00:25.729511",
  "status": "active"
}
```

### **Spark Streaming**
- MÃ©tricas por ventanas de tiempo
- Agregaciones por categorÃ­a
- AnÃ¡lisis de comportamiento
- Trends y patrones

---

## ğŸ” **Monitoreo**

### **Verificar MÃ©tricas en Redis**
```bash
# Ver todas las mÃ©tricas
docker exec redis-metrics redis-cli GET "metrics:dashboard"

# Ver claves disponibles
docker exec redis-metrics redis-cli KEYS "metrics:*"

# Monitorear en tiempo real
watch -n 1 'docker exec redis-metrics redis-cli GET "metrics:dashboard" | jq'
```

### **Logs de CDC Redis Producer**
```bash
# Ejecutar con logs visibles
python nico-scripts/cdc_redis_producer.py

# Logs esperados:
# âœ… ConexiÃ³n a Redis establecida
# âœ… Consumer Kafka CDC configurado
# ğŸ“¥ CDC Event - Topic: transaction, Op: c
# ğŸ’° TransacciÃ³n procesada: ID=1234, Total=$99.99
# ğŸ“Š MÃ©tricas actualizadas en Redis: 5 eventos procesados
```

### **Logs de Spark Streaming**
```bash
# Ver logs de Spark
python nico-scripts/spark-streaming/realtime_metrics_producer.py

# Logs esperados:
# ğŸš€ Realtime Metrics Producer inicializado
# ğŸ“Š Esperando datos de Kafka para procesar...
# ğŸ”„ Procesando batch 1 con 5 filas
# ğŸ“Š MÃ©tricas actualizadas en Redis
```

---

## âš™ï¸ **ConfiguraciÃ³n**

### **CDC Redis Producer**
- **Bootstrap Servers**: `localhost:9092`, `localhost:9093`, `localhost:9094`
- **Redis**: `localhost:6379`
- **Group ID**: `cdc-redis-producer-{timestamp}`
- **Auto Offset Reset**: `earliest`
- **Update Frequency**: Cada 5 eventos

### **Spark Streaming**
- **Spark Master**: `local[*]`
- **Watermark**: 10 segundos
- **Window Size**: 30 segundos
- **Batch Interval**: Por defecto

---

## ğŸ”§ **Troubleshooting**

### **CDC Redis Producer no recibe eventos**
1. **Verificar Debezium**: `curl http://localhost:8083/connectors`
2. **Verificar Topics**: `docker exec kafka1 kafka-topics.sh --list --bootstrap-server localhost:19092`
3. **Verificar Redis**: `docker exec redis-metrics redis-cli ping`

### **Spark Streaming no encuentra topics**
1. **Verificar configuraciÃ³n de topics** en el script
2. **Verificar conectividad**: Usar puertos internos (`19092`) para Kafka
3. **Revisar logs**: Buscar errores de `UNKNOWN_TOPIC_OR_PARTITION`

### **MÃ©tricas no se actualizan**
1. **Verificar que CDC Redis Producer estÃ© procesando eventos**
2. **Verificar logs**: Buscar mensajes de "MÃ©tricas actualizadas en Redis"
3. **Verificar claves Redis**: `KEYS metrics:*`

---

## ğŸ“ˆ **Performance**

### **CDC Redis Producer**
- âœ… **Alto throughput**: Procesa ~18K eventos en 15 segundos
- âœ… **Bajo overhead**: Sin Spark, consumo mÃ­nimo de memoria
- âœ… **Tiempo real**: ActualizaciÃ³n cada 5 eventos

### **Spark Streaming**
- âœ… **AnÃ¡lisis complejos**: Ventanas, agregaciones, joins
- âœ… **Escalabilidad**: Se adapta a volÃºmenes altos
- âœ… **Fault tolerance**: Checkpointing automÃ¡tico

---

## ğŸ’¡ **Recomendaciones**

1. **Usar CDC Redis Producer** para mÃ©tricas bÃ¡sicas en tiempo real
2. **Usar Spark Streaming** para anÃ¡lisis complejos y agregaciones avanzadas
3. **Ejecutar ambos en paralelo** para cobertura completa
4. **Monitorear Redis** para verificar que las mÃ©tricas se actualizan
5. **Verificar Debezium** regularmente para asegurar CDC activo
